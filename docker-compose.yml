services:
  db:
    image: timescale/timescaledb:latest-pg15
    environment:
      POSTGRES_USER: cylvy
      POSTGRES_PASSWORD: cylvy_secure_password
      POSTGRES_DB: cylvy_analyzer
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      # Migrations are now handled by the application, not docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U cylvy"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      DATABASE_URL: postgresql://cylvy:cylvy_secure_password@db:5432/cylvy_analyzer
      REDIS_URL: redis://redis:6379
      SECRET_KEY: ${SECRET_KEY:-development-secret-key-change-in-production-min-32-chars}
      JWT_SECRET_KEY: ${JWT_SECRET_KEY:-dev-jwt-secret-change-in-production}
      ENVIRONMENT: development
      STORAGE_PATH: /app/storage
      SKIP_AUTH: true
      
      # API Keys (set via environment or configure in admin portal)
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      SCALE_SERP_API_KEY: ${SCALE_SERP_API_KEY:-}
      SCRAPINGBEE_API_KEY: ${SCRAPINGBEE_API_KEY:-}
      SCALESERP_WEBHOOK_URL: ${SCALESERP_WEBHOOK_URL:-}
      SCALESERP_NOTIFICATION_EMAIL: ${SCALESERP_NOTIFICATION_EMAIL:-}
      COGNISM_API_KEY: ${COGNISM_API_KEY:-}
      YOUTUBE_API_KEY: ${YOUTUBE_API_KEY:-}
      
      # DataForSEO Configuration
      DATAFORSEO_LOGIN: ${DATAFORSEOKEY:-}
      DATAFORSEO_PASSWORD: ${DATAFORSEOPW:-}
      
      # Google Ads API Configuration
      GOOGLE_ADS_DEVELOPER_TOKEN: ${GOOGLE_ADS_DEVELOPER_TOKEN:-}
      GOOGLE_ADS_CLIENT_ID: ${GOOGLE_ADS_CLIENT_ID:-}
      GOOGLE_ADS_CLIENT_SECRET: ${GOOGLE_ADS_CLIENT_SECRET:-}
      GOOGLE_ADS_REFRESH_TOKEN: ${GOOGLE_ADS_REFRESH_TOKEN:-}
      GOOGLE_ADS_LOGIN_CUSTOMER_ID: ${GOOGLE_ADS_LOGIN_CUSTOMER_ID:-}
      GOOGLE_ADS_CUSTOMER_ID: ${GOOGLE_ADS_CUSTOMER_ID:-}
      
      # Generic Dimensions Feature Configuration
      GENERIC_DIMENSIONS_ENABLED: true
      OPENAI_MODEL_GENERIC_ANALYSIS: gpt-5-nano
      EVIDENCE_ANALYSIS_TIMEOUT: 45
      MAX_DIMENSIONS_PER_ANALYSIS: 20
      DYNAMIC_PROMPT_MAX_LENGTH: 16000
      
      # Performance Configuration
      DEFAULT_SCRAPER_CONCURRENT_LIMIT: 80  # Utilize most of ScrapingBee's 100 concurrent capacity
    ports:
      - "8001:8000"
    volumes:
      - ./backend:/app
      - ./backend/storage:/app/storage
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: >
      sh -c "
        echo 'Initializing database...' &&
        python -m app.db.migrate init &&
        echo 'Database ready. Starting application...' &&
        uvicorn app.main:app --host 0.0.0.0 --port 8000
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: development
    environment:
      NODE_ENV: development
      NEXT_PUBLIC_WS_URL: ws://localhost:8001/ws
      BACKEND_URL: http://backend:8000
      DOCKER_ENV: true
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    depends_on:
      - backend
    command: npm run dev

volumes:
  postgres_data:
  redis_data:

